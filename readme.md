
# üìÑ README.md: Proyecto ETL y Dashboard de Incidentes de Tr√°nsito

## üöó An√°lisis de Incidentes de Tr√°nsito en Puebla, M√©xico

### Descripci√≥n del Proyecto

Este proyecto implementa un *pipeline* de Extracci√≥n, Transformaci√≥n y Carga (**ETL**) para procesar datos **geoespaciales** de incidentes de tr√°nsito en la ciudad de Puebla, correspondientes a junio de 2021. Los datos son limpiados, normalizados y cargados en una base de datos **SQLite**. Posteriormente, se utiliza una aplicaci√≥n interactiva desarrollada con **Streamlit** para visualizar las m√©tricas clave, la distribuci√≥n geogr√°fica (mapa) y el an√°lisis de los incidentes por colonia.

**Tecnolog√≠as Clave:** Python, Pandas, **GeoPandas**, SQLAlchemy, Streamlit.

-----

## üì¶ Estructura del Repositorio y Entregables

El repositorio est√° organizado profesionalmente para separar el c√≥digo, la configuraci√≥n y los datos fuente.

| Carpeta/Archivo | Contenido |
| :--- | :--- |
| `src/` | Contiene el c√≥digo fuente de Python (ETL y Dashboard). |
| `config/` | Contiene el archivo de configuraci√≥n (`config.yaml`).|
| `data/` | Contiene el archivo GeoJSON de la fuente de datos.|
| `requirements.txt` | Lista de dependencias necesarias.|
| `incidents.db` | Base de datos SQLite (Generada por el pipeline).|
| `README.md` | Este documento.|

### C√≥digo Fuente (Detalle)

  * `src/orchestrator.py`: Script principal para la ejecuci√≥n del pipeline.
  * `src/etl_extract.py`: Funci√≥n para cargar los datos GeoJSON.
  * `src/etl_transform.py`: L√≥gica de limpieza, normalizaci√≥n y creaci√≥n de campos de an√°lisis.
  * `src/etl_load.py`: Funci√≥n para cargar el DataFrame transformado a la base de datos.
  * `src/dashboard.py`: Aplicaci√≥n Streamlit para la visualizaci√≥n de datos.

-----

## üöÄ Instrucciones de Uso

Para replicar y ejecutar el proyecto, siga los siguientes pasos:

### 1\. Preparaci√≥n del Entorno

Aseg√∫rese de tener Python (versi√≥n 3.8+) instalado. Clone el repositorio y navegue al directorio ra√≠z.

#### ‚ö†Ô∏è Instalaci√≥n y Activaci√≥n del Entorno Geoespacial

Este proyecto utiliza **GeoPandas**. Si ya tienes el entorno Conda llamado `etl-geo`, ¬°act√≠valo primero\!

```bash
conda activate etl-geo
```

Si a√∫n no has creado el entorno, la forma m√°s estable de instalar las dependencias geoespaciales es:

```bash
conda create -n etl-geo python=3.9
conda activate etl-geo
conda install -c conda-forge geopandas
```

Una vez que el entorno est√© activo, instale el resto de las librer√≠as del proyecto:

```bash
# Instalar dependencias restantes (pandas, streamlit, sqlalchemy, etc.)
pip install -r requirements.txt
```

### 2\. Crear y Configurar la Base de Datos

La base de datos se crea autom√°ticamente al ejecutar el pipeline por primera vez.

#### Esquema de la Tabla (SQL)

La tabla `road_incidents` en la base de datos `incidents.db` utiliza el siguiente esquema:

```sql
-- Esquema de la tabla road_incidents
CREATE TABLE IF NOT EXISTS road_incidents (
    id_incidente TEXT PRIMARY KEY,
    fecha DATETIME,
    hora TEXT,
    dia_semana TEXT,
    tipo_incidente TEXT,
    longitud REAL,
    latitud REAL,
    delegacion TEXT,
    colonia TEXT,
    calle TEXT,
    tipo_hecho TEXT,
    tipo_enerv TEXT,
    estado TEXT,
    lesionados INTEGER,
    muertos INTEGER,
    vehiculos_involucrados INTEGER
);
```

### 3\. Correr el Pipeline (ETL)

Con el entorno `(etl-geo)` activo, ejecute el orquestador:

```bash
python src/orchestrator.py
```

### 4\. Lanzar el Dashboard

Con el entorno activo:

```bash
streamlit run src/dashboard.py
```

-----

## üñºÔ∏è Capturas de Pantalla del Dashboard

### Vista General y Filtros

El dashboard inicia con los filtros vac√≠os y muestra las m√©tricas clave, el mapa de incidentes y el gr√°fico de colonias.

### An√°lisis de Distribuci√≥n

El gr√°fico de Top 10 Colonias se muestra con un ancho considerable, permitiendo una f√°cil identificaci√≥n de las zonas con mayor concentraci√≥n de incidentes.

-----
